{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1ce288e",
   "metadata": {},
   "source": [
    "# Task 5D – Teil 2: Datenvorbereitung & Äußerungsextraktion\n",
    "\n",
    "**Umfang dieses Notebooks (Teil 2):**\n",
    "\n",
    "1. Laden und Parsen der `spk_*.vtt`-Transkriptdateien\n",
    "2. Extraktion von Sprecher-IDs, Zeitstempeln und Äußerungstexten pro Session\n",
    "3. Laden der jeweiligen `speaker_to_cluster.json`-Dateien\n",
    "4. Verknüpfung der Äußerungen mit den zugehörigen Sprecher-Cluster-Zuordnungen\n",
    "5. Persistieren der bereinigten Daten als `.parquet`-Dateien für schnelle Wiederverwendung\n",
    "\n",
    "> **Hinweis:** Dieses Notebook setzt die abgeschlossenen Schritte aus Teil 1 voraus (Daten-Download & -Entpackung). Es bereitet die Datengrundlage für semantisches Feature Engineering in Teil 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a257d478",
   "metadata": {},
   "source": [
    "## 1) Bibliotheken laden & Konfiguration vorbereiten\n",
    "\n",
    "In diesem Schritt werden die benötigten Bibliotheken geladen und zentrale Parameter aus der Datei `run_config.json` eingelesen.\n",
    "\n",
    "Dazu gehören insbesondere:\n",
    "\n",
    "* das Projektverzeichnis (`PROJECT_ROOT`)\n",
    "* die Pfade zu den entpackten Rohdaten (`raw/train`, `raw/dev`)\n",
    "* vorbereitende Strukturen zur weiteren Verarbeitung\n",
    "\n",
    "> Ziel ist es, die im Setup definierte Umgebung reproduzierbar weiterzuverwenden und eine einheitliche Grundlage für die Verarbeitung der VTT- und JSON-Dateien zu schaffen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0828cce2-810d-4488-9fff-1128988116f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q --user webvtt-py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc04d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Verzeichnis: /home/ercel001/AUVIS/task5D_ml_prototype/data/raw/train\n",
      "Dev-Verzeichnis:   /home/ercel001/AUVIS/task5D_ml_prototype/data/raw/dev\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# 1) Imports und Laden der Konfiguration\n",
    "# -----------------------------------------------\n",
    "\n",
    "# Standardbibliotheken\n",
    "import json                     # Zum Laden der gespeicherten Konfiguration (run_config.json)\n",
    "from pathlib import Path        # Plattformunabhängige Arbeit mit Dateipfaden\n",
    "\n",
    "# Datenverarbeitung\n",
    "import pandas as pd             # Für spätere Verarbeitung und Speicherung als DataFrame/Parquet\n",
    "\n",
    "from tqdm import tqdm  # Fortschrittsbalken für Schleifen\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Projektverzeichnis definieren (wie in Teil 1 bekannt)\n",
    "# -----------------------------------------------------\n",
    "# Hinweis: Bei Bedarf anpassen, falls du in einem anderen Verzeichnis arbeitest.\n",
    "PROJECT_ROOT = Path.home() / \"AUVIS/task5D_ml_prototype\"\n",
    "\n",
    "# Pfad zur Konfigurationsdatei (wurde in Teil 1 erzeugt)\n",
    "cfg_path = PROJECT_ROOT / \"run_config.json\"\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Konfigurationsdatei einlesen und als Dictionary laden\n",
    "# -----------------------------------------------------\n",
    "with open(cfg_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Pfade zu den entpackten Trainings- und Entwicklungsdaten\n",
    "# -----------------------------------------------------\n",
    "RAW_TRAIN = Path(cfg[\"data\"][\"raw_train\"])\n",
    "RAW_DEV   = Path(cfg[\"data\"][\"raw_dev\"])\n",
    "\n",
    "# Ausgabe zur Kontrolle\n",
    "print(\"Train-Verzeichnis:\", RAW_TRAIN)\n",
    "print(\"Dev-Verzeichnis:  \", RAW_DEV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc27c299",
   "metadata": {},
   "source": [
    "## 2) VTT-Dateien parsen\n",
    "\n",
    "In diesem Schritt werden alle `spk_*.vtt`-Dateien pro Session eingelesen und geparst.\n",
    "Diese enthalten Zeitstempel sowie die zugehörigen Transkripte einzelner Sprecheräußerungen.\n",
    "\n",
    "Ziel ist es, pro Datei eine strukturierte Tabelle mit folgenden Spalten zu erzeugen:\n",
    "\n",
    "* `session_id`: Sitzungskennung (abgeleitet aus dem Dateipfad)\n",
    "* `speaker_id`: Kennung des Sprechers (abgeleitet aus dem Dateinamen)\n",
    "* `start_s`: Startzeitpunkt der Äußerung (in Sekunden)\n",
    "* `end_s`: Endzeitpunkt der Äußerung (in Sekunden)\n",
    "* `text`: Transkribierter Text der Äußerung\n",
    "\n",
    "Diese Daten bilden die Grundlage für die spätere Verknüpfung mit den Cluster-Zuordnungen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "165af66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# 2) VTT-Dateien parsen\n",
    "# ---------------------------------------------\n",
    "# Ziel dieses Blocks:\n",
    "# - Einzelne WebVTT-Dateien (spk_*.vtt) einlesen\n",
    "# - Zeitstempel, Sprecher-ID und Text extrahieren\n",
    "# - Ergebnis als strukturierter DataFrame zurückgeben\n",
    "\n",
    "import re\n",
    "import webvtt  # Bibliothek zum Einlesen von .vtt-Dateien (Web Video Text Tracks)\n",
    "\n",
    "def infer_session_id(path: Path) -> str:\n",
    "    \"\"\"\n",
    "    Ermittelt die Session-ID robust aus dem Dateipfad.\n",
    "    Typische Struktur: .../session_XX/labels/spk_003.vtt\n",
    "    - Bevorzugt den nächstgelegenen Ordnernamen, der mit 'session' beginnt\n",
    "      und Ziffern enthält (z. B. 'session_00', 'session_132').\n",
    "    - Fallback: eine Ebene über 'labels' bzw. parent-of-parent.\n",
    "    \"\"\"\n",
    "    # Kandidaten: vom Dateistandort nach oben laufen\n",
    "    for p in [path.parent, *path.parents]:\n",
    "        name = p.name.lower()\n",
    "        if name.startswith(\"session\") and any(ch.isdigit() for ch in name):\n",
    "            return p.name  # originaler Name, nicht lowercased\n",
    "    # Falls kein 'session_*' gefunden wurde: eine Ebene höher nehmen, wenn vorhanden\n",
    "    return path.parents[1].name if len(path.parents) > 1 else path.parent.name\n",
    "\n",
    "def infer_speaker_id(path: Path) -> str:\n",
    "    \"\"\"\n",
    "    Extrahiert die Sprecher-ID robust aus dem Dateinamen.\n",
    "    Beispiele:\n",
    "      - 'spk_003.vtt' -> '003'\n",
    "      - 'spk_5.vtt'   -> '5'\n",
    "      - '003.vtt'     -> '003'\n",
    "    Fallback: kompletter Stem, falls keine Ziffern gefunden werden.\n",
    "    \"\"\"\n",
    "    stem = path.stem  # Dateiname ohne Suffix\n",
    "    m = re.search(r'(\\d+)', stem)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    # falls das Schema 'spk_xxx' ohne Ziffern wäre (unwahrscheinlich), Prefix entfernen\n",
    "    return stem.replace(\"spk_\", \"\").strip()\n",
    "\n",
    "def parse_vtt_file(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Liest eine VTT-Datei ein und gibt ein DataFrame mit standardisierten Spalten zurück:\n",
    "      - session_id: Sitzungskennung (aus Pfad ermittelt, z. B. 'session_00')\n",
    "      - speaker_id: Sprecherkennung (aus Dateiname ermittelt)\n",
    "      - utt_id:     eindeutige Äußerungs-ID (kombiniert aus session, speaker, index)\n",
    "      - start_s / end_s: Start- und Endzeit (Sekunden)\n",
    "      - text:       Transkribierter Text der Äußerung\n",
    "    \"\"\"\n",
    "    utts = []\n",
    "\n",
    "    session_id = infer_session_id(path)\n",
    "    speaker_id = infer_speaker_id(path)\n",
    "\n",
    "    # Jede Caption im VTT durchlaufen (eine Caption = eine Äußerung)\n",
    "    for i, caption in enumerate(webvtt.read(path)):\n",
    "        # caption.text kann Zeilenumbrüche enthalten → trimmen\n",
    "        txt = caption.text.strip() if hasattr(caption, \"text\") else \"\"\n",
    "        utts.append({\n",
    "            \"session_id\": session_id,\n",
    "            \"speaker_id\": speaker_id,\n",
    "            \"utt_id\": f\"{session_id}_{speaker_id}_{i:04d}\",\n",
    "            \"start_s\": caption.start_in_seconds,\n",
    "            \"end_s\": caption.end_in_seconds,\n",
    "            \"text\": txt,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(utts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d7978f",
   "metadata": {},
   "source": [
    "## 3) Laden und Zusammenführen der VTT-Dateien je Split\n",
    "\n",
    "Alle WebVTT-Dateien (`spk_*.vtt`) werden pro Split (Train / Dev) rekursiv eingelesen, geparst und in einem einheitlichen DataFrame zusammengeführt.\n",
    "Dies ermöglicht eine konsistente Weiterverarbeitung der Sprecheräußerungen über alle Sitzungen hinweg.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bb37778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing train: 100%|██████████| 291/291 [00:01<00:00, 193.24it/s]\n",
      "Parsing dev: 100%|██████████| 139/139 [00:00<00:00, 255.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (19076, 6)\n",
      "Dev:   (8561, 6)\n",
      "\n",
      "Train – Anzahl Sessions: 56\n",
      "session_id\n",
      "session_84    539\n",
      "session_58    458\n",
      "session_62    453\n",
      "session_86    450\n",
      "session_24    445\n",
      "session_25    439\n",
      "session_85    439\n",
      "session_22    433\n",
      "session_83    430\n",
      "session_59    428\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Dev – Anzahl Sessions: 25\n",
      "session_id\n",
      "session_132    407\n",
      "session_43     405\n",
      "session_40     401\n",
      "session_44     397\n",
      "session_42     389\n",
      "session_136    387\n",
      "session_133    381\n",
      "session_134    362\n",
      "session_137    356\n",
      "session_55     354\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# 3) VTTs je Split laden und kombinieren\n",
    "# ---------------------------------------------\n",
    "# Ziel dieses Blocks:\n",
    "# - Alle VTT-Dateien für einen Split (z. B. train oder dev) rekursiv finden\n",
    "# - Jede Datei parsen (parse_vtt_file)\n",
    "# - Konsolidierten DataFrame für den gesamten Split erzeugen\n",
    "\n",
    "from tqdm import tqdm  # Fortschrittsbalken für Schleifen\n",
    "\n",
    "def load_vtts(split_dir: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Lädt alle VTT-Dateien im angegebenen Verzeichnis (z. B. raw/train oder raw/dev),\n",
    "    parst sie einzeln mit der Funktion `parse_vtt_file`, und gibt einen kombinierten DataFrame zurück.\n",
    "\n",
    "    Parameter:\n",
    "    ----------\n",
    "    split_dir : Path\n",
    "        Wurzelverzeichnis des jeweiligen Splits, z. B. \".../data/raw/train\"\n",
    "\n",
    "    Rückgabe:\n",
    "    ---------\n",
    "    pd.DataFrame\n",
    "        Konsolidierter DataFrame mit allen Sprecheräußerungen dieses Splits.\n",
    "    \"\"\"\n",
    "    all_utts = []\n",
    "\n",
    "    # Alle passenden VTT-Dateien rekursiv sammeln (häufig liegen sie unter .../session_XX/labels/spk_*.vtt)\n",
    "    vtt_files = list(split_dir.rglob(\"spk_*.vtt\"))\n",
    "    if not vtt_files:\n",
    "        print(f\"⚠️ Keine VTT-Dateien unter {split_dir} gefunden (Pattern 'spk_*.vtt').\")\n",
    "        return pd.DataFrame(columns=[\"session_id\",\"speaker_id\",\"utt_id\",\"start_s\",\"end_s\",\"text\"])\n",
    "\n",
    "    for vtt_path in tqdm(vtt_files, desc=f\"Parsing {split_dir.name}\"):\n",
    "        df = parse_vtt_file(vtt_path)\n",
    "        if not df.empty:\n",
    "            all_utts.append(df)\n",
    "\n",
    "    if not all_utts:\n",
    "        print(f\"⚠️ Keine Utterances aus {split_dir} extrahiert.\")\n",
    "        return pd.DataFrame(columns=[\"session_id\",\"speaker_id\",\"utt_id\",\"start_s\",\"end_s\",\"text\"])\n",
    "\n",
    "    return pd.concat(all_utts, ignore_index=True)\n",
    "\n",
    "# ---------------------------\n",
    "# Anwendung auf beide Splits\n",
    "# ---------------------------\n",
    "df_train_utts = load_vtts(RAW_TRAIN)\n",
    "df_dev_utts   = load_vtts(RAW_DEV)\n",
    "\n",
    "# Ergebnisübersicht\n",
    "print(\"Train:\", df_train_utts.shape)\n",
    "print(\"Dev:  \", df_dev_utts.shape)\n",
    "\n",
    "# Schneller Plausibilitätscheck: Haben wir jetzt mehrere Sessions?\n",
    "print(\"\\nTrain – Anzahl Sessions:\", df_train_utts[\"session_id\"].nunique())\n",
    "print(df_train_utts[\"session_id\"].value_counts().head(10))\n",
    "\n",
    "print(\"\\nDev – Anzahl Sessions:\", df_dev_utts[\"session_id\"].nunique())\n",
    "print(df_dev_utts[\"session_id\"].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4604d371-bf26-4d48-a7d2-24e3a7cb10c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train – Anzahl Sessions: 56\n",
      "session_id\n",
      "session_84    539\n",
      "session_58    458\n",
      "session_62    453\n",
      "session_86    450\n",
      "session_24    445\n",
      "session_25    439\n",
      "session_85    439\n",
      "session_22    433\n",
      "session_83    430\n",
      "session_59    428\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Dev – Anzahl Sessions: 25\n",
      "session_id\n",
      "session_132    407\n",
      "session_43     405\n",
      "session_40     401\n",
      "session_44     397\n",
      "session_42     389\n",
      "session_136    387\n",
      "session_133    381\n",
      "session_134    362\n",
      "session_137    356\n",
      "session_55     354\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train – Anzahl Sessions:\", df_train_utts[\"session_id\"].nunique())\n",
    "print(df_train_utts[\"session_id\"].value_counts().head(10))\n",
    "\n",
    "print(\"\\nDev – Anzahl Sessions:\", df_dev_utts[\"session_id\"].nunique())\n",
    "print(df_dev_utts[\"session_id\"].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35e2138",
   "metadata": {},
   "source": [
    "## 4) Laden der Cluster-Zuordnung und Verknüpfung mit den Äußerungen\n",
    "\n",
    "Für jede Sitzung wird die Datei `speaker_to_cluster.json` geladen, welche die Zuordnung einzelner Sprecher-IDs zu Konversations-Clustern enthält.\n",
    "Die Zuordnungen werden mit den zuvor extrahierten Äußerungen (`spk_*.vtt`) pro Session zusammengeführt, sodass jede Äußerung einem spezifischen Gesprächscluster zugewiesen werden kann.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f45cd71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# 4) Laden der Cluster-Zuordnung und Verknüpfung mit den Äußerungen\n",
    "# ---------------------------------------------\n",
    "# Ziel dieses Blocks:\n",
    "# - Für jede Session die Datei speaker_to_cluster.json laden\n",
    "# - Diese enthält ein Dictionary: {speaker_id: cluster_id}\n",
    "# - Alle Zuordnungen in ein globales Mapping überführen: (session_id, speaker_id) → cluster_id\n",
    "# - Dieses Mapping auf alle Äußerungen anwenden, um jeder Zeile im DataFrame einen Cluster zuzuweisen\n",
    "\n",
    "def load_clusters(split_dir: Path):\n",
    "    \"\"\"\n",
    "    Lädt alle speaker_to_cluster.json-Dateien im angegebenen Split-Verzeichnis\n",
    "    und baut ein Mapping (session_id, speaker_id) → cluster_id auf.\n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "\n",
    "    for json_path in split_dir.rglob(\"speaker_to_cluster.json\"):\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            session_mapping = json.load(f)\n",
    "\n",
    "            # Session-ID korrekt aus Ordnerstruktur ziehen\n",
    "            # typischer Pfad: .../session_132/labels/speaker_to_cluster.json\n",
    "            if json_path.parent.name == \"labels\":\n",
    "                session_id = json_path.parent.parent.name\n",
    "            else:\n",
    "                session_id = json_path.parent.name\n",
    "\n",
    "            for spk_id, cluster in session_mapping.items():\n",
    "                mapping[(session_id, spk_id)] = cluster\n",
    "\n",
    "    return mapping\n",
    "\n",
    "# Cluster-Mappings separat für Trainings- und Dev-Split laden\n",
    "cluster_train = load_clusters(RAW_TRAIN)\n",
    "cluster_dev   = load_clusters(RAW_DEV)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Cluster-Zuordnung auf die Äußerungs-DataFrames anwenden\n",
    "# ---------------------------------------------\n",
    "\n",
    "def assign_cluster(df, cluster_map):\n",
    "    \"\"\"\n",
    "    Ergänzt das DataFrame um eine neue Spalte 'cluster',\n",
    "    basierend auf dem Mapping (session_id, speaker_id) → cluster_id.\n",
    "    Wenn keine Zuordnung existiert, wird -1 eingetragen.\n",
    "    \"\"\"\n",
    "    return df.assign(\n",
    "        cluster=df.apply(\n",
    "            lambda row: cluster_map.get((row[\"session_id\"], row[\"speaker_id\"]), -1),\n",
    "            axis=1\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Anwendung der Funktion auf Trainings- und Dev-Daten\n",
    "df_train_utts = assign_cluster(df_train_utts, cluster_train)\n",
    "df_dev_utts   = assign_cluster(df_dev_utts, cluster_dev)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5871d583",
   "metadata": {},
   "source": [
    "## 5) Persistenz der Äußerungsdaten als Parquet-Dateien\n",
    "\n",
    "Die verarbeiteten und mit Clustern angereicherten DataFrames werden im **Apache Parquet-Format** gespeichert.\n",
    "Dieses Format ermöglicht eine **kompakte Speicherung**, **schnelles Laden** sowie **spaltenbasierten Zugriff** und ist daher ideal für die weitere Verarbeitung in Notebook 3 und darüber hinaus.\n",
    "\n",
    "Die Speicherung erfolgt jeweils getrennt für Trainings- und Entwicklungsdaten (`train.parquet` / `dev.parquet`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21f6842e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gespeichert:\n",
      " - train_utterances_multisession.parquet (0.58 MB)\n",
      " - dev_utterances_multisession.parquet (0.30 MB)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# 5) Persistenz der Äußerungsdaten als Parquet\n",
    "# ---------------------------------------------\n",
    "# Ziel dieses Blocks:\n",
    "# - Speichern der train/dev-DataFrames mit Sprecheräußerungen + Cluster-Zuordnung\n",
    "# - Format: Apache Parquet (kompakt, performant, spaltenbasiert)\n",
    "# - Speicherort: ~/AUVIS/task5D_ml_prototype/data/prepared/\n",
    "\n",
    "# Zielverzeichnis vorbereiten\n",
    "out_dir = PROJECT_ROOT / \"data\" / \"prepared\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)  # idempotent: erstellt auch Zwischenordner\n",
    "\n",
    "# Neue, saubere Multi-Session-Dateien speichern\n",
    "out_train = out_dir / \"train_utterances_multisession.parquet\"\n",
    "out_dev   = out_dir / \"dev_utterances_multisession.parquet\"\n",
    "\n",
    "df_train_utts.to_parquet(out_train, index=False)\n",
    "df_dev_utts.to_parquet(out_dev, index=False)\n",
    "\n",
    "# Übersicht der gespeicherten Dateien ausgeben\n",
    "print(\"Gespeichert:\")\n",
    "for f in [out_train, out_dev]:\n",
    "    print(\" -\", f.name, f\"({f.stat().st_size/1e6:.2f} MB)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45294905",
   "metadata": {},
   "source": [
    "### ✅ Nächste Schritte (für Teil 3)\n",
    "\n",
    "Fahre mit dem nächsten Notebook **Teil 3: Feature Engineering & Embedding-Generierung** fort, sobald die Parquet-Dateien erfolgreich gespeichert wurden:\n",
    "\n",
    "* Extrahieren semantischer Merkmale aus dem Äußerungstext mittels vortrainierter Sentence-Embedding-Modelle\n",
    "* Persistieren der Embeddings (pro Äußerung) zur späteren Nutzung im Clustering\n",
    "* Vorbereitung weiterführender Merkmale (optional): prosodisch, visuell, kontextuell\n",
    "* Speicherung als strukturierte Feature-Dateien für Teil 4 (Clustering & Analyse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212b313a-69ac-4940-8fd7-7b7d47a0b372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
